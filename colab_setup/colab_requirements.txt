# Google Colab Compatible Requirements
# Exact version specifications for Google Colab CUDA 12.5 environment
# Python 3.10 optimized (best package compatibility)
# Generated: 2025-08-25 - Python 3.10 compatible versions

# ================================
# CORE DEEP LEARNING FRAMEWORK
# ================================
# PyTorch ecosystem - CUDA 12.1 compatible with PyTorch 2.7 (prevents auto-upgrade to 2.8)
torch==2.7.1 -f https://download.pytorch.org/whl/torch_stable.html
torchvision==0.22.1 -f https://download.pytorch.org/whl/torch_stable.html
torchaudio==2.7.1 -f https://download.pytorch.org/whl/torch_stable.html

# ================================
# CRITICAL AI MODEL DEPENDENCIES
# ================================
# Mamba State Space Models - Direct GitHub wheels to avoid Colab build issues
# causal-conv1d 1.5.2 with CUDA 12, PyTorch 2.7, Python 3.10, cxx11abiFALSE for Colab
https://github.com/Dao-AILab/causal-conv1d/releases/download/v1.5.2/causal_conv1d-1.5.2+cu12torch2.7cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
# mamba-ssm 2.2.5 with CUDA 12, PyTorch 2.7, Python 3.10, cxx11abiFALSE for Colab (VERIFIED WORKING)
https://github.com/state-spaces/mamba/releases/download/v2.2.5/mamba_ssm-2.2.5+cu12torch2.7cxx11abiFALSE-cp310-cp310-linux_x86_64.whl

# Transformer models and acceleration
transformers==4.44.0
accelerate==0.34.0
einops==0.8.0

# ================================
# TRADING SYSTEM CORE
# ================================
# Uncertainty quantification (Python 3.10 optimized)
mapie==0.9.2

# Market data and financial analysis
yfinance==0.2.65
pandas==2.3.2
numpy==2.2.6
scipy==1.15.3

# Machine learning utilities
scikit-learn==1.5.2

# ================================
# TECHNICAL ANALYSIS
# ================================
# Technical indicators
Ta-Lib==0.6.5
pandas-ta==0.3.14b0

# ================================
# VISUALIZATION AND MONITORING  
# ================================
matplotlib==3.10.5
seaborn==0.13.2
plotly==6.3.0

# ================================
# SYSTEM UTILITIES
# ================================
# Logging and configuration
loguru==0.7.3
pydantic==2.11.7
pydantic-settings==2.7.0

# File handling
toml==0.10.2
tomli==2.0.1

# HTTP and networking
requests==2.32.3
urllib3==2.2.2

# ================================
# DEVELOPMENT AND TESTING
# ================================
# Testing framework
pytest==8.3.2
pytest-cov==6.2.1

# Code quality
black==24.8.0
isort==6.0.1

# ================================
# JUPYTER AND COLAB INTEGRATION
# ================================
# Jupyter utilities (often pre-installed in Colab)
ipywidgets==8.1.3
tqdm==4.66.5

# ================================
# OPTIONAL PERFORMANCE ENHANCEMENTS
# ================================
# GPU acceleration for PyTorch operations
ninja==1.11.1.1

# Fast JSON processing
orjson==3.10.7

# Memory optimization
psutil==6.0.0

# ================================
# GRAPH NEURAL NETWORKS (for SAMBA)
# ================================
# PyTorch Geometric for graph neural networks - CUDA 12.1 compatible
torch-geometric==2.6.1
torch-scatter==2.1.2 -f https://data.pyg.org/whl/torch-2.4.0+cu121.html
torch-sparse==0.6.18 -f https://data.pyg.org/whl/torch-2.4.0+cu121.html
torch-cluster==1.6.3 -f https://data.pyg.org/whl/torch-2.4.0+cu121.html
torch-spline-conv==1.2.2 -f https://data.pyg.org/whl/torch-2.4.0+cu121.html

# ================================
# VERSION NOTES
# ================================
# Key compatibility constraints:
# - Python: 3.10 or 3.11 (MAPIE doesn't support 3.12 yet)
# - CUDA: 12.5 (Google Colab default driver)
# - PyTorch: 2.7.1+cu121 (prevents auto-upgrade to 2.8 which breaks mamba_ssm)
# - mamba-ssm: 2.2.5 (latest stable with CUDA 12 support, compiled for PyTorch 2.7)
# - causal-conv1d: 1.5.2 (CUDA 12 compatible, compiled for PyTorch 2.7)
#
# Installation order is important:
# 1. PyTorch first (provides CUDA base)
# 2. mamba-ssm and causal-conv1d (critical dependencies)
# 3. transformers and accelerate (model loading)
# 4. Everything else in any order
#
# Expected installation time:
# - First run (building wheels): 10-15 minutes
# - Subsequent runs (from cache): 1-2 minutes